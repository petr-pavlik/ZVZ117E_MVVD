# Závislost dvou veličin {#seq-zavislost}

## Korelace {#sec-korelace}

Korelace je vztah mezi dvěma náhodnými veličinami. Zkoumá, zda se jedna ze zkoumaných veličin mění, pokud se zároveň mění i druhá. Korelace nezkoumá příčinnost, nelze tedy jednoznačně určit závislou a nezávislou proměnnou.

Míru korelace dvou veličin posuzujeme korelačním koeficientem. V případe normality u obou veličin lze použít **Paersonův** korelační koeficient,

$$
r_{xy} = \dfrac{\sum(x_i - \bar{x})(y_i - \bar{y})}{\sqrt{\sum(x_i - \bar{x})^2}\sqrt{\sum(y_i - \bar{y})^2}}
$$ {#eq-pearson}

přičemž platí $r_{xy}\in\langle-1;1\rangle$. Alternativně můžeme použít neparametrický výpočet **Spearmana**, založený na diferencích pořadí pozorovaných hodnot, které definujeme jako $d_i = x_{ri} - y_{ri}$

$$
\rho = r_s = 1 - \dfrac{6\sum_{i=1}^{n}d_i^2}{n(n^2-1)} 
$$ {#eq-spearman}

::: callout-tip
## Cvičení

1. Napište vlastní funkci, které pro dané vektory `x` a `y` spočítá korelační Spearmanův koeficient.\
  a) Nejprve je nutné identifikovat pořadí,\
  b) dále spočítat kvadrát vzdáleností,\
  c) a po dosazení počtu měření $n$ dosadit do rovnice.\
2. Vyzkoušejte obě funkce na datech

Řešení:\
```{r, eval=FALSE}
#| code-fold: true
sp_k <- function(x, y) {
  rank_x <- rank(x) 
  rank_y <- rank(y) 
  d <- rank_x - rank_y 
  d_sq <- sum(d^2) 
  n <- length(x) 
  1 - ((6 * d_sq) / (n*(n^2 - 1))) 
}
```


```{r, eval=FALSE}
sp_k(_, _)
cor(_, _, method = "Spearman")
```

3. Pokuste se odhadnout korelační koeficient následujících veličin

```{r, echo=FALSE, fig.align='center'}
par(mfrow = c(2, 2))
plot(x = sin(seq(-1, 4, length.out = 100) + rnorm(100, sd = 0.4)), 
     xlab = "", 
     ylab = "", 
     axes = FALSE)
plot(x = sort(c(sin(seq(-1, 4, length.out = 50)), 
                cos(seq(-3, 1, length.out = 50)))) + rnorm(n = 100, 
                                                           sd = 1.4), 
     xlab = "", 
     ylab = "", 
     axes = FALSE)
plot(x = 1:100/10, 
     y = 5 + rnorm(100, sd = 5.5), 
     xlab = "", 
     ylab = "", 
     axes = FALSE, 
     xlim = c(-10, 25), 
     ylim = c(-10, 20))
plot(x = 1:100 * rnorm(100, sd = 500), 
     xlab = "", 
     ylab = "", 
     axes = FALSE)
```
:::

`pairs()`

## Kovariance

## Regresní model

Narozdíl od korelace, v regresní analýze sledujeme příčinnou závislost. Identifikujeme **nezávislou proměnnou** a **závislou proměnnou**. Míru závislosti posuzujeme pomocí lineárního regresního modelu. Cílem regrese je proložit naměřenými body přímku, která nejlépe vystihuje vztah mezi proměnnými.

$$
y = \beta_0 + \beta_1x
$$ kde $y$ je závislá proměnná, $x$ je nezávislá proměnná, $\beta_0$ je počátek (intercept) a $\beta_1$ je sklon přímky.

Lineární model regresního typu definujeme v R pomocí funkce `lm()`, které na první pozici dosazujeme výraz ve formátu rovnice `formula`, např. `lm(y ~ x)`. Model vyhodnocujeme funkcí `summary` a mezi sebou porovnáváme pomocí kritérií zohledňující vysvětlenou variabilitu/věrohodnost modelu a jeho komplexnost, např. **Akaikeho informační kritérium**.

$$
\text{AIC} = 2k - 2\ln(\hat{L})
$$ kde $k$ je počet volných parametrů modelu a $\hat{L}$ je věrohodnostní funkce modelu.

##### Cvičení {.unnumbered}

  1. Uvažujme následující data, kde předpokládáme příčinnou závislost $y$ na $x$.

```{r}
dfr <- data.frame(
  x <- c( 3.93,  3.83,  7.11,  6.98,  7.87,  9.11, 10.04,  9.99, 10.11, 10.93, 
         11.01, 11.93, 11.94, 11.88, 11.82, 12.98, 13.04, 13.04, 13.11, 13.99, 
         13.97, 13.99, 13.97, 15.08, 14.93, 14.86, 15.89, 16.15, 17.08, 17.18, 
         16.96, 17.95, 18.14, 18.09, 18.05, 19.04, 19.08, 19.07, 20.11, 20, 
         20,    20.14, 19.92, 22.13, 23.09, 23.9 , 23.95, 24.06, 23.95, 24.94
  ),
  y <- c( 1.93, 10.01,  3.73, 22.09, 15.86, 10.09, 18.09, 25.91, 34.09, 16.89, 
         28.04, 13.95, 19.98, 23.98, 27.78, 26.19, 33.85, 33.96, 45.88, 25.96, 
         35.89, 60.  , 80.03, 20.06, 25.92, 54.03, 31.96, 40.12, 32.03, 39.95, 
         50.2 , 41.91, 55.92, 75.92, 83.89, 35.94, 45.94, 67.85, 32.05, 48.11, 
         52.11, 55.95, 64.02, 65.9 , 53.94, 69.92, 92.1 , 92.78, 99.03, 85.09)
)
```
  
  2. Sestrojme lineární model `md1`

```{r}
md1 <- lm(formula = y ~ x, data = dfr)
```

  3. Struktura objektu `md1` je komplexní, můžeme vybírat jednotlivé proměnné k dalším účelům, například pro tvorbu grafů.

```{r}
str(md1, 1) #<1>
```
1. Vypíšeme strukturu objektu do první hierarchické úrovně


```{r}
with(data = dfr, 
     expr = plot(x, 
                 y, 
                 xlim = c(0, 30), 
                 ylim = c(md1$coefficients[1], 
                          max(md1$fitted.values) + 2)))
abline(md1$coefficients, col = "orangered")
abline(v = 0, lty = "dashed")
abline(h = md1$coefficients[1], lty = "dashed")

```

  4. Model vyhodnotíme pomocí `summary`

```{r}
summary(md1)
```

Souhrn obsahuje původní zadání v podobě rovnice, dále identifikované koeficienty modelu, významnost závislosti indikuje přítomnost jedné nebo více `*` u vysvětlující proměnné; dále lze vyčíst podíl vysvětlené variabiltiy `Adjusted R-squared:  0.6417`.\

```{r}
par(mfrow = c(2, 2))
plot(md1, 1:4)
```

R dále poskytuje grafické nástroje k posouzení vhodnosti zvoleného modelu. Zde nás budou zajímat zejména **residua** modelu. Dle prvního grafu by mohl model se závislostí na polynomu být lepší volbou.\

Pokusme se sestavit alternativní model s kvadratickou vysvětlující proměnnou.

```{r}
md2 <- lm(y ~ poly(x, 2))
summary(md2)
```

```{r}
par(mfrow = c(2, 2))
plot(md2, 1:4)
```

```{r}
with(data = dfr, 
     expr = plot(x, y, xlim = c(0, 30)))
pred <- predict(md2)
ix <- sort(dfr$x, index.return=T)$ix
lines(x[ix], pred[ix], col = 'orangered')
```

Srovnejme modely vzájemně

```{r}
AIC(md1, md2)
```

::: callout-tip
## Cvičení

  1. Prozkoumejte závislost odtoku na velikosti povodí\ 

| Povodí | velikost $x_i$ | pořadí | odtok $y_i$ | pořadí | rozdíl $d_i$ | $d_i^2$ |      
|--------|----------------|--------|-------------|--------|--------------|---------|     
| 1      |                |        |             |        |              |         |     
| 2      |                |        |             |        |              |         |      
| 3      |                |        |             |        |              |         |      
| 4      |                |        |             |        |              |         |      
| 5      |                |        |             |        |              |         |     
| 6      |                |        |             |        |              |         |     
| 7      |                |        |             |        |              |         |     
| 8      |                |        |             |        |              |         |     
| 9      |                |        |             |        |              |         |     
| 10     |                |        |             |        |              |         |     
  
:::
